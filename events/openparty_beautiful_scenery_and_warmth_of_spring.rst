OpenParty &quot;熙春暖意&quot;
##############################
:date: 2010-03-31 23:21
:category: Event
:status: draft

"`熙春暖意`_"是农历新年后的第一期OpenParty活动。当天北京的天气虽不像活动的标题一样美丽----迎接我们的是一个寒意依旧，沙尘满天的日子，不过这不能阻挡众多热爱分享和交流的朋友的脚步。此次活动话题众多，还有一位前辈史无前例地贡献了一连三场话题，实在佩服。参与人数再度达到百人，现场到处都可以看到三两一组对技术/文化/其它各种各样话题进行交流的人，气场还是那么足。
还是简要叙述下自己参与的三个话题：

UI/UE设计讨论

这个是个现场讨论的话题，在话题组织者的带领下，大家针对UI/UE设计领域的问题各抒己见，自己在不少方面也有了更新的了解。限于讨论性话题的分散性，在这里仅简单记录下印象比较深刻的观点。

话题组织者引导大家做了这样一个用户体验试验：请一位用户扮作盲人，另一位用户帮助他读出鼠标所指处的文字来引导'盲人'用户完成某一个特定的任务。在这个看似简单的实验里，却能发现很多平常难以窥见的细节，如屏幕阅读会读出很多不需要的东西，从而给用户造成困惑等。事实上这个实验也是行业中的实际案例，在国外的某个网站项目中，有盲人用户致电客服，提出了很多实用性上的问题。其实不只是针对盲人，一个文字冗余、不直观、不对用户友好的界面设计，也是用户体验产品的直接障碍。
抓住用户目标性和随意性浏览的特点，达到用户和网站需求的平衡

通过调查、用户测试、观察、客观反馈、访问数据等方式进行用户的研究，"提升正面反馈，消除负面反馈"。

用户体验的度量。

现场参与的朋友也谈到了很多：

新版本上线前实施AB测试，引导
10％的用户到新版本设计。查看用户是否"尖叫"（即对新设计有尖锐的抵触），如果存在尖叫状况，新设计下线->进入Rollback设计流程。

谈到现今互联网领域的UI/UE问题，除了一些设计以及体验上的问题以外，还有一位朋友提出了"网站的服务意识差，用户的被服务意识也很差，如果更好地沟通以及交流反馈，在有些时候也是问题。用户积极参与的意识很重要。"

--------

把街机搬回家

由 `@gokeeper`_
带来的，当天让无数技术男燃起的话题。讲述了如何把原汁原味的街机搬回家，要注意：使用的不是寻常的模拟器、PC摇杆，而是真正的街机硬件、街机框体和摇杆，当然还包括投入代币这种可勾起无数人美好回忆的体验。

其实如果想照葫芦画瓢实现一个也不是什么大问题，gokeeper的解决方案也说明了，山寨产品＋淘宝＋用心实现的激情基本上可以解决全部的问题。

自己简单记录下来的几个要点，供大家参阅：

-  街机主板的游戏卡槽上，连接一款通过电脑来提供游戏的转接卡，价格不贵。
-  山寨厂街机框体可定制，价格 1200
   元左右，包括框体、29寸CRT、定制的摇杆和按钮。注意相较之下日本原厂的使用近十年的框体还要万余元，山寨厂的街机框体，价格便宜量又足。
-  电视的扫描频率问题。显卡默认输出的刷新率过高，需通过更换驱动等特殊方式，降到15KHz左右
-  淘宝上订购的精巧的投币装置 40元
-  整套设备还具备传统街机难以想象的扩展能力，可以通过KAI与网上的玩家进行对战，还可以与Xbox
   360进行连接，在庞大的街机框体上执行家用机游戏。

--------

网页正文提取初步

宋进亮博士带来的话题，整个话题其实也是自然语言识别领域的一小部分内容，不过宋博士的开场就先声明："整个应用不限定特定行业，演讲中不用忽悠人的词"，于是整个话题也就在轻松的环境下讲述了众多非常有料的内容。

现场演示的实例： 从Blog以及网站页面里面抓取正文

大体上看，目前的文字抓取方式，无外乎以下三种方法：

通过正则表达式抓取：通过诸如 BeautifulSoup 这样的工具进行。

-  方法简单，但是性能可能会有问题。与所抓取的目标网页依赖过大，一旦网页格式发生变动，就需要对抓取的方式进行一些更新。出于偷懒的原则，如果程序能够自动识别变化，那样才比较完美。

标签特征，本话题所述方法即属于此类别

基于视觉的处理，跨越标签领域，有一些的技术门槛，此话题暂不涉及。

-  （在2009年2月的 `OpenParty"有狐"`_ 活动中，有位来自雅虎中国的朋友分享了一篇在服务器端使用Firefox进行网页抓取和内容识别工作的话题，实际上就是基于视觉的处理实现）

基于文本密度算法的实现，是上述的标签特征类别的方法。

基本公式：纯文本字符数/HTML源码字符数

原始方法

#. 记录HTML标签起始位置
#. 统计HTML源码首尾包括的字符数和其中的文本字符数

使用Python的matplotlib对统计的结果进行图示查看，从直方图中直观地可以发现，网页中有一部分的文本密度明显高于其它部分。在整个过程中还可以使用Tidy软件包来清理HTML代码，实例中演示的Sina页面，使用Tidy进行清理后进行识别的效果要好很多。

从实际状况出发，对算法进行小调整：从以前的文本前后判断，变成标签前后判断

优点：数据的整体性更好。

缺点：数据的分布情况不够直观，有干扰。可以适当地加入一些值的过滤方式来实现

整个实现方法所使用的代码量：加入注释以及模式过滤的原脚本大约有200多行Python代码，如果是根据网上论文的原始实现，大约100多行Python代码

所参考的论文中描述的人工智能文本识别方法：

使用神经网络模型

-  可使用FANN库，有相应的Python封装

采用原始的一刀切方式，会有丢行的现象产生。

个别行的密度会比较小。

神经网络模型的算法，可以采用机器进行学习的方式进行。不过要注意，学习所采用的原料和实际使用中所针对的目标相似度的关系也很重要。学习的量较少，可能会达不到完成任务所需的精度；而学习量过大，出现"过学习"的状况，也可能会出现过度吻合，从而导致对目标数据的变化非常敏感。

其它智能方法

针对HTML标签序列

-  统计方法
-  贝叶斯
-  马尔可夫
-  CRF

不过为了达成我们的目标，找到最窍门的地方，才是最关键的。比如在很多应用场合下，看似粗旷的'一刀切'方法可能效果也非常不错。

这里介绍的自然语言识别只是一个具体的分支应用，而这个大领域还包括很多其他的内容，如逐渐变热的分词技术，也是值得关注的。

总的来说，自然语言识别技术需要根据应用领域、应用环境来提供相应的解决方案。没有银弹！

我一知半解的记录肯

.. _熙春暖意: http://www.beijing-open-party.org/2010/03/beijing-open-party-2010-03-event-preview/
.. _@gokeeper: http://twitter.com/gokeeper
.. _OpenParty"有狐": http://cnborn.net/blog/2009/03/openparty-mozilla-event.html
